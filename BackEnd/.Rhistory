str_detect(engine, "turbocharged|turbo") ~ "Turbocharged",
str_detect(engine, "supercharged") ~ "Supercharged",
TRUE ~ "None"
),
engine_configuration = case_when(
str_detect(engine, "v[0-9]+") ~ "V",
str_detect(engine, "w[0-9]") ~ "W",
str_detect(engine, "h[0-9]") ~ "Flat",
str_detect(engine, "i[0-9]+") ~ "Inline",
str_detect(engine, "flat") ~ "Flat",
str_detect(engine, "cylinder") ~ "straight",
str_detect(engine, "straight") ~ "Straight",
str_detect(engine, "rotary") ~ "Rotary",
TRUE ~ "Inline"
)
)
df$engine_horsepower <- HorsePower
df$engine_displacement <- engine_displacement
df$cylinder_number <- cylinder_Number
#engine_valves <- data.frame( df %>%pull(engine) %>% str_match(".([0-9]+)(?=v)")) %>% select(X1) %>% pull()
#df$engine_valves <- engine_valves
return(df)
}
#install.packages("splitTools")
#install.packages("xgboost")
library(DT)
library(shiny)
library(bslib)
library(tidyverse)
library(bsicons)
library(purrr)
library(splitTools)
library(xgboost)
## Dataset variables and column names
Cars_Kaggle<- read.csv("../Used_car_prices/DATASETS/train.csv")
source("Global Variables.R")
options(max.print = 1e6)
output_file <- "console_output.txt"
sink(output_file)
source("Global Variables.R")
options(max.print = 1e6)
output_file <- "console_output.txt"
sink(output_file)
source("Global Variables.R")
setwd("E:/nani projects/DATA SCIENCE/version4.0/BackEnd")
options(max.print = 1e6)
output_file <- "console_output.txt"
sink(output_file)
source("Global Variables.R")
source("./Functions/Core.R")
source("./Functions/Caller.R")
## clean Duplicate values
DealWith_Duplicates(Cars_Kaggle)
## clean missing values
ImputedData <- DealWith_MissingValues(Cars_Kaggle)
## Adding New column for category type of car
## outliers
ImputedData <- DealWith_Outliers(ImputedData,Cars_Kaggle)
## extracting engine features
Engine_Featured_Data <- DealWith_ExtractingEngineFeatures(ImputedData)
## final iteration of missing values
Engine_Featured_Data <- DealWith_MissingValuesFinal(Engine_Featured_Data)
#Engine_Featured_Data_Scaled <- Engine_Featured_Data %>% mutate(price = log(price))
##  Conversions
ProcessedData <- DealWith_Converstions(Engine_Featured_Data)
inds <- Splitter(ProcessedData)
Web_Purpose_ProcessedData <- ProcessedData
write.csv(Web_Purpose_ProcessedData, file = "Datasets/Web_Purpose_ProcessedData.csv")
write.csv(Web_Purpose_ProcessedData, file = "../FrontEnd/DATASETS/Web_Purpose_ProcessedData.csv")
## Feature selection using backward elimination is done already and these are main features obtained,
#The code for this is commented since this is not required to run everytime
## Backward Eliminator
#options(max.print = 1e6)
#source("./Models/BackwardEliminator.R")
## Scaling Data
#ProcessedData <- Scaler_R(ProcessedData)
ProcessedData <- ProcessedData %>% select(c(price,
brand,
ModelYear=model_year,Milage=milage,EngineHorsepower=engine_horsepower,
FuelType=fuel_type,Transmission=transmission,Accident=accident,
EngineTechnology=engine_technology,EngineSpecial=engine_special,EngineConfiguration=engine_configuration))
# Dimensionality reduction
# reason for linear model:
# feature selection has already been applied to remove unnecessary features, ensuring that the dataset retains only the most relevant ones,
# It is not necessarily a condition to avoid dimension reduction technique if we apply feature selection but
# applying further Dimensionality reduction could risk removing valuable information. since the model is able to take less time after all the optimizations
# we concluded to not use Dimensionalityreduction
# reason for XGBoost:
# XGBoost is designed to efficiently handle large feature sets and can automatically assess feature importance during training.
# Due to its robust ability to capture complex relationships, Dimensionality reduction is not necessary.
# In fact, reducing the feature set might remove important interactions that XGBoost could otherwise leverage for better predictions.
# split data
ProcessedData_Train <- ProcessedData[inds$train, ]
ProcessedData_Valid <- ProcessedData[inds$valid, ]
ProcessedData_Test <- ProcessedData[inds$test, ]
write.csv(ProcessedData, file = "Datasets/ProcessedData.csv")
write.csv(ProcessedData, file = "../FrontEnd/DATASETS/ProcessedData.csv")
write.csv(ProcessedData_Train, file = "Datasets/ProcessedData_Train.csv")
write.csv(ProcessedData_Train, file = "../FrontEnd/DATASETS/ProcessedData_Train.csv")
write.csv(ProcessedData_Test, file = "Datasets/ProcessedData_Test.csv")
write.csv(ProcessedData_Test, file = "../FrontEnd/DATASETS/ProcessedData_Test.csv")
write.csv(ProcessedData_Valid, file = "Datasets/ProcessedData_Valid.csv")
write.csv(ProcessedData_Valid, file = "../FrontEnd/DATASETS/ProcessedData_Valid.csv")
## Onehot encoded DATA
OnehotencodedData <- OneHotEncoder_R(ProcessedData)
write.csv(OnehotencodedData, file = "Datasets/OnehotencodedData.csv")
write.csv(OnehotencodedData, file = "../FrontEnd/DATASETS/OnehotencodedData.csv")
OnehotencodedData_Train <- OnehotencodedData[inds$train, ]
write.csv(OnehotencodedData_Train, file = "Datasets/OnehotencodedData_Train.csv")
write.csv(OnehotencodedData_Train, file = "../FrontEnd/DATASETS/OnehotencodedData_Train.csv")
OnehotencodedData_Valid <- OnehotencodedData[inds$valid, ]
write.csv(OnehotencodedData_Valid, file = "Datasets/OnehotencodedData_Valid.csv")
write.csv(OnehotencodedData_Valid, file = "../FrontEnd/DATASETS/OnehotencodedData_Valid.csv")
OnehotencodedData_Test <- OnehotencodedData[inds$test, ]
write.csv(OnehotencodedData_Test, file = "Datasets/OnehotencodedData_Test.csv")
write.csv(OnehotencodedData_Test, file = "../FrontEnd/DATASETS/OnehotencodedData_Test.csv")
#Train data
library(dplyr)
Records<- ProcessedData_Valid %>% select(-price)
actual_prices <- ProcessedData_Valid$price
source("./Models/Linearmodel.R")
ggplot(fold_summary_lm_long, aes(x = Fold, y = Value, color = Metric, group = Metric)) +
geom_line(size = 1) +
geom_point(size = 2) +
labs(
title = "Linear Regression Metrics Across Folds",
x = "Fold",
y = "Metric Value",
color = "Metric"
)
lr_metrics
lr_metrics
View(lr_metrics)
lr_metrics[11]
lr_metrics %>% nrow(41)
lr_metrics %>%  slice(41:45)
lr_metrics %>%  slice(41:45)
library(dplyr)
lr_metrics %>%  slice(41:45)
lr_metrics[41:45, ]
lr_metrics[41:45, ]
BestParamets_LM<- lr_metrics[41:45, ]
BestParamets_LM
View(BestParamets_LM)
ggplot(BestParamets_LM, aes(x = Fold, y = Value, color = Metric, group = Metric)) +
geom_line(size = 1) +
geom_point(size = 2) +
labs(
title = "Linear Regression Metrics Across Folds",
x = "Fold",
y = "Metric Value",
color = "Metric"
)
View(BestParamets_LM)
ggplot(BestParamets_LM) +
geom_line(, aes(x = Fold,y = RMSE)) +
geom_line(, aes(x = Fold,y = MAE)) +
geom_line(, aes(x = Fold,y = R2)) +
geom_line(, aes(x = Fold,y = MAPE)) +
labs(
title = "Linear Regression Metrics Across Folds",
x = "Fold",
y = "Metric Value",
color = "Metric"
)
ggplot(BestParamets_LM) +
geom_line( aes(x = Fold,y = RMSE)) +
geom_line( aes(x = Fold,y = MAE)) +
geom_line( aes(x = Fold,y = R2)) +
geom_line( aes(x = Fold,y = MAPE)) +
labs(
title = "Linear Regression Metrics Across Folds",
x = "Fold",
y = "Metric Value",
color = "Metric"
)
ggplot(BestParamets_LM) +
geom_line( aes(x = Fold,y = RMSE)) +
geom_line( aes(x = Fold,y = MAE)) +
geom_line( aes(x = Fold,y = R2)) +
labs(
title = "Linear Regression Metrics Across Folds",
x = "Fold",
y = "Metric Value",
color = "Metric"
)
ggplot(BestParamets_LM) +
geom_line( aes(x = Fold,y = RMSE),colour = "green") +
geom_line( aes(x = Fold,y = MAE)) +
geom_line( aes(x = Fold,y = R2)) +
labs(
title = "Linear Regression Metrics Across Folds",
x = "Fold",
y = "Metric Value",
color = "Metric"
)
ggplot(BestParamets_LM) +
geom_line(aes(x = Fold, y = RMSE, color = "RMSE"), size = 1) +  # Green for RMSE
geom_line(aes(x = Fold, y = MAE, color = "MAE"), size = 1) +    # Red for MAE
geom_line(aes(x = Fold, y = R2, color = "R2"), size = 1) +      # Blue for R2
geom_line(aes(x = Fold, y = MAPE, color = "MAPE"), size = 1) +  # Purple for MAPE
labs(
title = "Linear Regression Metrics Across Folds",
x = "Fold",
y = "Metric Value",
color = "Metric"
) +
scale_color_manual(values = c("RMSE" = "green", "MAE" = "red", "R2" = "blue", "MAPE" = "purple")) +
theme_minimal()
View(fold_summary_lm_long)
ggplot(BestParamets_LM) +
geom_line(aes(x = Fold, y = RMSE, color = "RMSE"), size = 1) +   # Green for RMSE
geom_line(aes(x = Fold, y = MAE, color = "MAE"), size = 1) +     # Red for MAE
geom_line(aes(x = Fold, y = R2, color = "R2"), size = 1) +       # Blue for R2
geom_line(aes(x = Fold, y = MAPE, color = "MAPE"), size = 1) +   # Purple for MAPE
labs(
title = "Linear Regression Metrics Across Folds",
x = "Fold",
y = "Metric Value",
color = "Metric"
) +
scale_color_manual(values = c(
"RMSE" = "green",
"MAE" = "red",
"R2" = "blue",
"MAPE" = "purple"
)) +
theme_minimal(base_size = 14) +
theme(
legend.position = "top",
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title = element_text(face = "bold")
)
ggplot(BestParamets_LM) +
geom_line(aes(x = Fold, y = RMSE, color = "RMSE"), size = 1) +   # Green for RMSE
geom_line(aes(x = Fold, y = MAE, color = "MAE"), size = 1) +     # Red for MAE
geom_line(aes(x = Fold, y = R2, color = "R2"), size = 1) +       # Blue for R2
geom_line(aes(x = Fold, y = MAPE, color = "MAPE"), size = 1) +   # Purple for MAPE
labs(
title = "Linear Regression Metrics Across Folds",
x = "Fold",
y = "Metric Value",
color = "Metric"
) +
scale_color_manual(values = c(
"RMSE" = "green",
"MAE" = "red",
"R2" = "blue",
"MAPE" = "purple"
)) +
theme(
legend.position = "top",
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title = element_text(face = "bold")
)
ggplot(BestParamets_LM) +
geom_line(aes(x = Fold, y = RMSE, color = "RMSE"), size = 1) +
geom_line(aes(x = Fold, y = MAE, color = "MAE"), size = 1) +
geom_line(aes(x = Fold, y = R2, color = "R2"), size = 1) +
geom_line(aes(x = Fold, y = MAPE, color = "MAPE"), size = 1) +
labs(
title = "Linear Regression Metrics Across Folds with best alpha",
x = "Fold",
y = "Metric Value",
color = "Metric"
) +
scale_color_manual(values = c(
"RMSE" = "green",
"MAE" = "red",
"R2" = "blue",
"MAPE" = "purple"
)) +
theme(
legend.position = "top",
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title = element_text(face = "bold")
)
ggplot(BestParamets_LM) +
geom_line(aes(x = Fold, y = RMSE, color = "RMSE"), size = 1) +
geom_line(aes(x = Fold, y = MAE, color = "MAE"), size = 1) +
geom_line(aes(x = Fold, y = R2, color = "R2"), size = 1) +
geom_line(aes(x = Fold, y = MAPE, color = "MAPE"), size = 1) +
labs(
title = "Linear Regression Metrics Across Folds with best alpha",
x = "Fold",
y = "Metric Value",
color = "Metric"
) +
scale_color_manual(values = c(
"RMSE" = "green",
"MAE" = "red",
"R2" = "blue",
"MAPE" = "purple"
)) +
theme(
legend.position = "top",
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title = element_text(face = "bold")
)
fold_summary_BestParamets_LM_long <- BestParamets_LM %>%
pivot_longer(cols = starts_with("Avg"), names_to = "Metric", values_to = "Value")
fold_summary_BestParamets_LM_long <- BestParamets_LM %>%
pivot_longer(cols = starts_with("Avg"), names_to = "Metric", values_to = "Value")
View(BestParamets_LM)
View(fold_summary_lm)
BestParamets_LM_long <- BestParamets_LM %>%
pivot_longer(cols = c("RMSE", "MAE", "R2", "MAPE"), names_to = "Metric", values_to = "Value")
BestParamets_LM_long
View(BestParamets_LM_long)
ggplot(BestParamets_LM_long, aes(x = Fold, y = Value, color = Metric)) +
geom_line(size = 1) +
geom_point(size = 2) +
facet_wrap(~ Metric, scales = "free_y") +  # Create a panel for each metric
labs(
title = "Linear Regression Metrics Across Folds",
x = "Fold",
y = "Metric Value"
) +
theme_minimal() +
theme(
legend.position = "none",  # Remove legend (each facet already represents a metric)
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title = element_text(face = "bold")
)
BestParamets_LM
View(BestParamets_LM)
ggplot(fold_summary_lm_long, aes(x = Fold, y = Value, color = Metric, group = Metric)) +
geom_line(size = 1) +
geom_point(size = 2) +
labs(
title = "XGBoost Metrics Across Folds",
x = "Fold",
y = "Metric Value",
color = "Metric"
)
ggplot(BestParamets_LM_long, aes(x = Fold, y = Value, color = Metric)) +
geom_line(size = 1) +
geom_point(size = 2) +
facet_wrap(~ Metric, scales = "free_y") +
labs(
title = "Linear Regression Metrics Across Folds",
x = "Fold",
y = "Metric Value"
) +
theme_minimal() +
theme(
legend.position = "none",
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title = element_text(face = "bold")
)
#Train data
library(dplyr)
Records<- ProcessedData_Valid %>% select(-price)
actual_prices <- ProcessedData_Valid$price
source("./Models/Linearmodel.R")
ggplot(BestParamets_LM_long, aes(x = Fold, y = Value, color = Metric)) +
geom_line(size = 1) +
geom_point(size = 2) +
facet_wrap(~ Metric, scales = "free_y") +
labs(
title = "Linear Regression Metrics Across Folds",
x = "Fold",
y = "Metric Value"
) +
theme_minimal() +
theme(
legend.position = "none",
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title = element_text(face = "bold")
)
fold_summary_lm_long
source("./Models/XGBoost.R")
xgb_metrics
prices_xgb <- predict_car_prices_XGB(Records)
cv_results_xgb
cv_results_xgb
View(cv_results_xgb)
cv_results_xgb
xgb_metrics <- extract_xgb_metrics(cv_results_xgb,5)
cv_results_xgb[1]
cv_results_xgb[[1]]
extract_xgb_metrics <- function(cv_results, num_folds=5) {
Df_cv_results_Xgb <- data.frame()
fold_index <- 1
for (variable in cv_results$fold_results) {
# Extract metrics for each CV
fold_metrics <- c(
Fold = fold_index,
RMSE = variable$rmse,
MAE = variable$mae,
R2 = variable$r2,
MAPE = variable$mape
)
Df_cv_results_Xgb <- rbind(Df_cv_results_Xgb, fold_metrics)
fold_index <- ifelse(fold_index == num_folds, 1, fold_index + 1)
}
colnames(Df_cv_results_Xgb) <- c("Fold", "RMSE", "MAE", "R2", "MAPE")
return(Df_cv_results_Xgb)
}
xgb_metrics <- extract_xgb_metrics(cv_results_xgb,5)
xgb_metrics
View(xgb_metrics)
BestParamets_XGB<- xgb_metrics[15:20, ]
fold_summary_xgb <- xgb_metrics %>%
group_by(Fold) %>%
summarize(
Avg_RMSE = mean(RMSE, na.rm = TRUE),
Avg_MAE = mean(MAE, na.rm = TRUE),
Avg_R2 = mean(R2, na.rm = TRUE),
)
fold_summary_xgb_long <- fold_summary_xgb %>%
pivot_longer(cols = starts_with("Avg"), names_to = "Metric", values_to = "Value")
# Plot for XGBoost
ggplot(fold_summary_xgb_long, aes(x = Fold, y = Value, color = Metric, group = Metric)) +
geom_line(size = 1) +
geom_point(size = 2) +
labs(
title = "XGBoost Metrics Across Folds",
x = "Fold",
y = "Metric Value",
color = "Metric"
)
BestParamets_XGB_long <- BestParamets_XGB %>%
pivot_longer(cols = c("RMSE", "MAE", "R2", "MAPE"), names_to = "Metric", values_to = "Value")
ggplot(BestParamets_XGB_long, aes(x = Fold, y = Value, color = Metric)) +
geom_line(size = 1) +
geom_point(size = 2) +
facet_wrap(~ Metric, scales = "free_y") +
labs(
title = "Linear Regression Metrics Across Folds",
x = "Fold",
y = "Metric Value"
) +
theme_minimal() +
theme(
legend.position = "none",
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title = element_text(face = "bold")
)
ggplot(BestParamets_XGB_long, aes(x = Fold, y = Value, color = Metric)) +
geom_line(size = 1) +
geom_point(size = 2) +
facet_wrap(~ Metric, scales = "free_y") +
labs(
title = "XGB Metrics Across Folds",
x = "Fold",
y = "Metric Value"
) +
theme_minimal() +
theme(
legend.position = "none",
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title = element_text(face = "bold")
)
prices_xgb
metrics_lm <- calculate_metrics(ProcessedData_Valid$price, prices_xgb)
metrics_xgb <- calculate_metrics(ProcessedData_Valid$price, prices_lm)
metrics_comparison <- data.frame(
Metric = c("RMSE", "MAE", "R2", "MAPE"),
Linear_Regression = unlist(metrics_lm),
XGBoost = unlist(metrics_xgb)
)
print(metrics_comparison)
print(metrics_comparison)
alpha=0.1
d_mean <- 0
lm_residuals <- actual_prices - prices_lm
xgb_residuals <- actual_prices - prices_xgb
residual_differences <- lm_residuals - xgb_residuals
n <- length(residual_differences)
mean_diff <- mean(residual_differences)
std_error <- sd(residual_differences) / sqrt(n)
t_critical <- qt(p = alpha / 2, df = n - 1, lower.tail = FALSE)
CI <- c(mean_diff - t_critical * std_error, mean_diff + t_critical * std_error)
cat("Confidence Interval (CI): ", CI, "\n")
cat("Confidence Interval (CI): ", CI, "\n")
# Hypothesis testing
cat("H0: There is no significant difference between XGB and LM (mean difference = 0).\n")
cat("H1: There is a significant difference between XGB and LM (mean difference â‰  0).\n")
if (CI[1] <= 0 && CI[2] >= 0) {
cat("Conclusion: Fail to reject H0. The difference in predictions between XGB and LM is NOT statistically significant at 99% confidence.\n")
} else {
cat("Conclusion: Reject H0. The difference in predictions between XGB and LM is statistically significant at 90% confidence.\n")
}
prices_xgb
source("Model_Comparision.R")
extract_xgb_metrics(cv_results_xgb,5)
BestParamets_XGB<- xgb_metrics[15:20, ]
fold_summary_xgb <- xgb_metrics %>%
group_by(Fold) %>%
summarize(
Avg_RMSE = mean(RMSE, na.rm = TRUE),
Avg_MAE = mean(MAE, na.rm = TRUE),
Avg_R2 = mean(R2, na.rm = TRUE),
)
BestParamets_XGB_long <- BestParamets_XGB %>%
pivot_longer(cols = c("RMSE", "MAE", "R2", "MAPE"), names_to = "Metric", values_to = "Value")
ggplot(BestParamets_XGB_long, aes(x = Fold, y = Value, color = Metric)) +
geom_line(size = 1) +
geom_point(size = 2) +
facet_wrap(~ Metric, scales = "free_y") +
labs(
title = "XGB Metrics Across Folds",
x = "Fold",
y = "Metric Value"
) +
theme_minimal() +
theme(
legend.position = "none",
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title = element_text(face = "bold")
)
